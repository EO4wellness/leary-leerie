# Udacity AI Fundamentals
* 2021-05-12 Started study 
* Invited by email to take this free course 
* [Udacity course link](https://www.udacity.com/course/ai-fundamentals--ud099?bsft_aaid=affd8710-61ff-4001-baca-1d4a7303381d&bsft_eid=ad60985b-18d9-30b1-f123-34893b099da5)
* [PlayList](
https://www.youtube.com/playlist?list=PLgoc4E_HHEUWTAwG6Smt39oLju90moDJr)


## Course Outline and Study Log:
* [Lesson 1](https://github.com/EO4wellness/leary-leerie/blob/master/AI-ML-topics/AI-Fundamentals.md#lesson-1-intro): Began and completed: 2021-05-12
* [Lesson 2](https://github.com/EO4wellness/leary-leerie/blob/master/AI-ML-topics/AI-Fundamentals.md#lesson-2) Began and completed: 2021-05-12. Created [Flashcards](https://www.brainscape.com/packs/udacity-ai-fundamentals-17974857) from this lesson's key-concepts: 2021-05-13.
* [Lesson 3](https://classroom.udacity.com/courses/ud099/lessons/7f7d3ee3-bcbb-45e1-a781-eac79dfe643f/concepts/597236a9-7538-4657-8843-3c6320cc22e3): Began and Completed study: 2021-05-14. Created [Flashcards](https://www.brainscape.com/packs/udacity-ai-fundamentals-17974857) from this lesson's key-concepts: 2021-05-14.
* [Lesson 4](https://classroom.udacity.com/courses/ud099/lessons/d2a77498-3bd4-466d-90ce-9bf572a2c467/concepts/9b018ae4-efe5-4f96-b283-18207bc2420d): 2021-05-16 Created Flashcards from this unit's glossary;
* Lesson 5 
* Lesson 6: 
* Lesson 7:

## Content Overview: 
### Lesson 1: Overivew of how Udacity works and how to set course-related goals to succeed. 

### Lesson 2: Introduction to AI Fundamentals
* In this lesson we'll learn:

   - Microsoft's cloud-based solutions for AI and Machine Learning.
   - The organization of an AI and ML Team and various stakeholders that take part in AI and ML initiatives.
   - A brief history of AI
   - The prerequisites for the rest of the course
   - When to use AI and ML, and when not?

* By the end of this lesson, you'll be ready and prepared for the rest of the course.

### Lesson 3: AI and ML Core Concepts
* In this lesson we'll learn:

   - The relationship between AI and ML.
   - The five workloads for AI and ML and have an understanding of the common use cases.
   - Responsible AI and the application of ethics to the topic of AI.
   - Responsible ML and the ethical responsibilities of researchers, data scientists, and employees at organizations performing machine learning tasks.
* By the end of this lesson, you will have a good idea of the main fundamental concepts we need to be able to start using AI and ML tools in Microsoft Azure.

### Lesson 4: Machine Learning
* In this lesson we'll learn:

   - Key Machine Learning Concepts to crafting a foundation for following lessons.
   - Different approaches to ML, such as Supervised, Unsupervised, Semi-Supervised and Reinforcement Learning
   - Core tasks in building AI and ML solutions including Automated ML and Azure ML.
   - An overview of Azure ML around Azure ML Designer and ML Pipelines.

* By the end of this lesson, you will have created three separate machine learning models using Azure Machine Learning and deployed two of them to production.

### Lesson 5: Computer Vision
* With this lesson, we will switch gears and focus on specialized AI services for specific AI and ML workloads. We'll learn:

   - Object Detection and Classification with Azure Computer Vision
   - Image Classification with Azure Custom Vision
   - Facial Recognition with Azure Face service.
   - Read text (OCR) with Azure Computer Vision
   - Extracting information from forms with Azure Form Recognizer

* By the end of this lesson, you will be ready to implement various capabilities of Azure Computer vision into your applications.


### Lesson 6: Natural Language Processing
* In this lesson, we'll focus on AI workloads that require Natural Human Language Understanding. We will learn:

   - Key Phrase and Entity extraction with Text Analytics to get insights about documents.
   - Intent extraction through Language Understanding to figure out what a sentence's goal is.
   - Speech recognition and synthesis of speech from text.
   - Text and Speech Translation
* By the end of this lesson, you will be ready to implement various NLP capabilities of Azure Cognitive Services into your applications. Some of these capabilities will be used in the next lesson when building conversational AI systems.

### Lesson 7: Conversational AI
* In this lesson, we'll build a knowledge base and craft conversational experiences between users and computers. We will learn:

   - What Conversational AI is.
   - Creating a knowledge base with Azure QnA Maker
   - Deploying an automated bot to Azure Bot Service
   - Using Azure Bot Service channels.
* By the end of this lesson, you will build a chatbot backed by a knowledge base from start to finish.

# Course Notes: 
## Lesson 1: Intro
* Welcome to Udacity 
* the Udacity Experience 
* Career Chat with your Instructors (insightful-worth watching video again)
* How to Succeed (great advice!)

## Lesson 2: 
1. Meet your Instructors
  - [Ciprian Jichici](https://www.linkedin.com/in/ciprianjichici/)
  - [Daron Yondem](https://www.linkedin.com/in/daronyondem/)
  - [Kevin Feasel](https://www.linkedin.com/in/kevin-feasel-5047167/)
  - [Kyle Bunting](https://www.linkedin.com/in/kylebunting/)
 
2. Introduction to AI Fundamentals 

Summary

In this course, we will focus on Microsoft's two primary cloud-based AI and ML services. Those are Azure Machine Learning service and Azure Cognitive Services.

    Azure Machine Learning service provides tools to build and deploy machine learning models for all skill levels.
    Azure Cognitive Services offer specialized AI services for specific AI workloads such as Computer Vision, Prediction / Forecasting, Anomaly Detection, Natural Language Processing, and Conversational AI.

Quiz Question
What would be a better fit if you were looking for more out-of-the-box functionality to deliver specialized services for specific AI workloads?
- Azure Machine Learning Service 
- Azure Cognitive services (correct answer) 

New Terms

    Anomaly Detection: Detecting data points that do not align with a recognized pattern across a set of data points.
    API: Application programming interfaces that are exposed to help multiple applications and systems interact with each other.
    Azure Cognitive Services: A suite of AI Services targeting specialized AI workloads to help developers implement AI capabilities into their solution with minimal AI and ML expertise.
    Azure Machine Learning: A cloud-based service that delivers a platform supporting the creation and deployment of Machine Learning Models.
    Computer Vision: A domain of artificial intelligence focused on processing and understanding visual inputs through complex machine learning algorithms.
    Intent: An intent represents the action the user wants to execute. It usually refers to a preferred action when a user delivers a sentence to be interpreted by the machine.
    Jupyter Notebook: A virtual notebook environment where developers can write notes and combine live code and visualizations into a single document.
    Machine Learning Model: A machine learning model is a logic that has been trained to recognize certain types of patterns.
    Machine Learning Operations (MLOps): The practice involves the automation of processes required to build and deliver end-to-end Machine Learning Models and experiences.
    Natural Language Processing: A domain of artificial intelligence focused on understanding human language and helping computers and humans interact through human language.

Additional Study Resources
    Visit [Microsoft's AI Strategy and Solutions learning path](https://docs.microsoft.com/en-us/learn/modules/azure-artificial-intelligence/) from Microsoft if you are interested in learning more about Azure AI services and Microsoft's AI Vision.


3. Course Overview - as outlined above 

4. Stakeholders
Summary
Artificial Intelligence and Machine Learning are team sport. The number of roles involved in AI and ML initiatives can vary based on the organizations' size. Most organizations start with a Machine Learning team and complement with an AI team moving forward.

Key stakeholders you may need to colaborate with: 
   - External Stakeholders: Executives, customers, and managers from other groups in the organization.
   - Data Scientists: They identify use cases and determine the suitable datasets and algorithms for experiments. They build the AI models.
   - Data Engineers: They focus on making the data available and accessible to data scientists integrating various data sources, optimizing access to data.
   - AI Architects: They connect data scientists, data engineers, software developers, and developer operations to get the solution up and running, including the assessment of infrastructure requirements.
   - ML Engineers: Subject matter experts in their area and make sure AI models are suitable for production use.
   - AI Developer: Focuses on the development and implementation of AI solutions.
   - Data Analyst: Uses machine learning to extract insights from data.

![AI-Team-External-Stakeholders](https://video.udacity-data.com/topher/2021/March/604f627c_20210315-aiml-team/20210315-aiml-team.png)

QUIZ: 
How do data scientists get to the data?
Correct. Data Engineers focus on integrating various data sources, optimizing access to data, and providing a self-service environment for those who need access to the data.

New Terms
    Experiment: In the context of AI and ML, experiment refers to using the AI and ML processes to see if a particular question can be answered with AI and ML, or a hypothesis can be supported or validated.
    Dataset: A dataset is a collection of data that is used to train the machine during the AI and ML processes.

Additional Resources
    If you are interested in learning more about evaluating and prioritizing AI investments in your organization, [Microsoft has a learning path for you](https://docs.microsoft.com/en-us/learn/modules/implement-ai-organization/).


5. History of AI and ML
Summary
Artificial Intelligence and Machine Learning adoption is increasing every day. The principles behind AI and ML, such as Mathematics, Economics, Neuroscience, Philosophy, Linguistics, and Computer Engineering, all have their fair share in today's AI and ML history.

   - 1943: McCulloch and Pitts created a model of a neuron. The thinking was that the ability to model a neuron would help create an artificial human brain and intelligence.
   - 1950: The first Turing test was announced. A machine hidden behind a curtain was tested by a human on the side of the curtain. If the tester could not identify the identity as a machine, it would have been a success for AI. No one passed a full Turing test so far, but just limited versions.
   - 1956: The first Artificial Intelligence conference in Dartmouth happened.
   - The 1960s: The first robot Shakey that incorporated robotics, computer vision, and natural language processing, was able to move boxes in a room.
   - The 1970s: Lack of computing resources resulted in a decrease in interest in AI. This period in AI History is now called AI Winter.
   - The 1980s-90s: The first autonomous trip from New York to LA was the "No Hands Across America". DeepBlue for Chess brought a lot of interest in AI.
   - The 2010s: AI defeated the human world champion at GO.

Quiz: 
Considering AI's history, which one is a slow down in progress and a reduction of interest in AI and ML?
Correct! AI winter defines the area where interest in AI decreased.

New Terms
    Autonomous: An autonomous system is a system that can accomplish a task without human involvement during the execution of the task.
    Go: An abstract strategy-based board game.
    Turing Test: A test where a human tested interacts with two entities, one machine, and one human, without knowing which one is which. The goal of the test is to assess if the tester can identify which one is the machine. If the tester can not determine the machine or is not sure, the machine passes the test.

Additional Resources
    [Watch the history of Shakey](https://www.youtube.com/watch?v=7bsEN8mwUB8), the first Robot to Embody Artificial Intelligence
    If you are looking for more granular details of Machine Learning History here is an [additional timeline with milestones](https://labelyourdata.com/articles/history-of-machine-learning-how-did-it-all-start/).



6. Prerequisites 
Summary

    You are expected to have fundamental programming knowledge in a programming language.
    You will need an active Azure Subscription and an Azure Resource Group. Below you can find instructions on how to get both.

Prerequisite 1: An Active Azure Subscription

You need an active Azure Subscription to complete the lessons in this course. If you don't have one, you can sign up for a free trial at https://azure.microsoft.com/free.

Prerequisite 2: Create an Azure resource group

During the course, you will create various Azure resources to be used in the lessons. You will need an Azure Resource Group to organize the resources you create. A resource group in Azure acts as a hosting container that can hold multiple Azure resources. The following steps will help you create a resource group in Azure.

   1  Open a web browser, navigate to the Azure portal, and sign in using the account associated with your Azure subscription.
   2  On the home page of the [Azure portal](https://portal.azure.com/), select Resource groups under the Azure services heading.

Resource groups is highlighted under the Azure services header on the Azure home page.

![Azure Services](https://video.udacity-data.com/topher/2021/February/60359490_resource-groups/resource-groups.png)

Resource groups

    On the Resource groups blade, select Add on the toolbar to create a new resource group.

The Add button on the Resource groups toolbar is highlighted.

![azure services](https://video.udacity-data.com/topher/2021/February/603608f1_resource-groups-add/resource-groups-add.png)

Add resource group

    On the Create a resource group Basics tab, enter the following:
        Subscription: Select the subscription you are using for this course.
        Resource group: Enter udacity-exercises or another name unique within your subscription.
        Region: Select any available region, but preferably one close to your location. Note, you will use this same region for all other resources you create during this course.

The values indicated above are entered into the create a resource group basics tab.

![resource group basic tab](![image](https://user-images.githubusercontent.com/55713583/118055976-af9c2900-b34e-11eb-8922-b8c22ac690dd.png)


Create a resource group basics tab

    Select Review + create and on the Review + create tab, ensure the validation passed message is displayed and then select Create.

The create a resource group review and create tab is displayed with the validation passed and create button highlighted.

![validation](![image](https://user-images.githubusercontent.com/55713583/118056013-bdea4500-b34e-11eb-8761-e543082c48e3.png)

"Review new resource group settings"


7. When to use and not to use AI
Summary
When not to use AI and ML?

    The lack of good, high-quality data would be an issue to get high confidence results. In this case, we suggest getting the data first.
    Do not use AI and ML if you are looking to get 100% correct answers at all times. Predictions and pattern recognition methods will not get you what you want. You have to be ok with wrong answers with varying confidence levels.
    The world is changing. Make sure your data and predictions help you within the confines of the nonstationary world. You canâ€™t use data from last year to predict healthcare or finance situations post COVID.

When to use AI and ML?

    If finding patterns is your primary goal, you are on the right path. Make sure your patterns are generalizable. You might be able to find a pattern of rainy days for the last year. But if that does not provide a good prediction for tomorrow, who cares about that pattern?
    You have to be ok with approximate solutions instead of exact solutions.

Quiz Question
In which scenario AI and ML might not be a good fit?
- Extracting sentiment from human speech 
- Predicting when someone can get cancer (Correct. Predicting when someone will get cancer suggests that they will get cancer. This goes into the area of looking for a 100% correct answer and will not be a good fit for AI and ML.)
- Predicting how long a player will play a game 
- predicting what books a book reader would like reading. 

8. Lesson Review
![review](https://video.udacity-data.com/topher/2021/March/60507005_20210316-lesson-review/20210316-lesson-review.png)

Summary
In this lesson, we took a peek at the world of AI and ML and prepared for what's next in the upcoming lessons. We learned:

    The tools and services that are available in Azure such as Azure Machine Learning and Azure Cognitive Services.
    The course agenda including topics ranging from AI and ML Core Concepts to Machine Learning, Computer Vision. Natural Language Processing and Conversational AI.
    Various stakeholders involved in AI and ML initiatives and the roles that are commonly found to be part of an AI and ML Team.
    The history of AI and ML.
    When we should use AI and ML and when we should not.

Now, you are ready to go to the next level. Enjoy the course.


9. Glossary: all the new terms we introduced in this lesson:
* Anomaly Detection: Detecting data points that do not align with a recognized pattern across a set of data points.
* API: Application programming interfaces that are exposed to help multiple applications and systems interact with each other.
* Autonomous: An autonomous system is a system that can accomplish a task without human involvement during the execution of the task.
* Azure Cognitive Services: A suite of AI Services targeting specialized AI workloads to help developers implement AI capabilities into their solution with minimal AI and ML expertise.
* Azure Machine Learning: A cloud-based service that delivers a platform supporting the creation and deployment of Machine Learning Models.
* Computer Vision: A domain of artificial intelligence focused on processing and understanding visual inputs through complex machine learning algorithms.
* Dataset: A dataset is a collection of data that is used to train the machine during the AI and ML processes.
* Experiment: In the context of AI and ML, experiment refers to using the AI and ML processes to see if a particular question can be answered with AI and ML, or a hypothesis can be supported or validated.
* Go: An abstract strategy-based board game.
* Intent: An intent represents the action the user wants to execute. It usually refers to a preferred action when a user delivers a sentence to be interpreted by the machine.
* Jupyter Notebook: A virtual notebook environment where developers can write notes and combine live code and visualizations into a single document.
* Machine Learning Model: A machine learning model is a logic that has been trained to recognize certain types of patterns.
* Machine Learning Operations (MLOps): The practice involves the automation of processes required to build and deliver end-to-end Machine Learning Models and experiences.
* Natural Language Processing: A domain of artificial intelligence focused on understanding human language and helping computers and humans interact through human language.
* Turing Test: A test where a human tested interacts with two entities, one machine, and one human, without knowing which one is which. The goal of the test is to assess if the tester can identify which one is the machine. If the tester can not determine the machine or is not sure, the machine passes the test.

## Lesson 3: 
1. Introduction and Lesson Overview
Welcome to the AI Fundamentals lesson about core concepts relating to artificial intelligence (AI) and machine learning (ML). Artificial intelligence is a branch of computer science dedicated to the notion of agents: computer systems with the ability to simulate thought. Since its genesis in the 1950s, artificial intelligence has remained a topic of interest in computer science, developing out into a number of sub-topics focused around search and optimization, pattern recognition, inference, and learning from experience. Implementations of artificial intelligence may be as simple as small, rule-based systems of behavior to move a character on a screen in a video game or as complex as multi-stage neural networks taking thousands of inputs to generate forecasts of tomorrow's stock market movements.

Throughout the lesson, we will gain an understanding of what Artificial Intelligence and Machine Learning are, as well as how they relate to one another. We will review common workloads for AI and ML, including examples of how they are used in practice today. We will additionally cover Responsible AI and Responsible ML guidelines, sets of practices to help promote ethics in artificial intelligence and machine learning, respectively.
Summary

This lesson will introduce you to some of the key concepts in artificial intelligence and machine learning, acting as a springboard to the remaining lessons in this nanodegree. In this lesson, we will learn about:

    What artificial intelligence and machine learning are, as well as how they relate to one another.
    Common artificial intelligence and machine learning workloads.
    The Responsible Artificial Intelligence project
    The Responsible Machine Learning project

This key information will act as the foundation for each subsequent lesson, as well as providing a primer on the topic of artificial intelligence.

2. Introducing AI and ML
Summary

Artificial intelligence is a branch of computer science dedicated to simulating human cognitive behavior. In the realm of artificial intelligence, we have machine learning, which allows a computer to learn without human intervention.

The process of developing an artificial intelligence system has four key steps:

    Data scientists build an artificial intelligence system using techniques. These techniques can include, but are not limited to, machine learning.
    The artificial intelligence system then trains machine learning models by studying patterns in the data.
    Data scientists observe the results of these machine learning models and subsequently optimizes them, most commonly by modifying the artificial intelligence system which generates these models.
    The process of training and optimization--steps 2 and 3--repeats until the model becomes accurate enough for its intended purpose. At this point, the model is capable of going into production.

New Terms

    Artificial Intelligence: the ability for a computer to simulate human cognitive behavior.
    Weak Artificial Intelligence: a narrow application of intelligence, focused on solving one problem. An example of this is a system which counts people who enter or leave a bus. All artificial intelligence systems today are considered weak AI.
    Strong Artificial Intelligence: a system which exhibits a human's ability to generalize and solve a variety of problems, including learning how to solve new problems without direct human programming. As of today, there are no strong AI systems in the world, and there remains debate in the academic community around whether strong AI is achievable.
    Super Artificial Intelligence: a system which surpasses a human's ability to generalize and solve problems. This is like strong AI, but the expectation is that the system is superior in every domain of problem-solving capability.
    Machine Learning: the process of combining algorithms and data to allow a computer to learn without human intervention.

Additional Resources

    Professor John McCarthy has a great set of [questions and answers](http://jmc.stanford.edu/artificial-intelligence/index.html) around the concept of Artificial Intelligence. One of these questions [pertains to the branches of AI](http://jmc.stanford.edu/artificial-intelligence/what-is-ai/branches-of-ai.html), showing the depth of what is available in this space. Note that these answers were written in 2007, prior to the resurgence of neural networks.
    The differences between [artificial intelligence and machine learning](https://azure.microsoft.com/en-us/overview/artificial-intelligence-ai-vs-machine-learning/). This page explains how artificial intelligence and machine learning relate to one another. It also emphasizes the AI and ML process, as well as explaining some of the capabilities of AI and ML.
    Artificial intelligence and machine learning are useful in a large number of industries. Dirk Mayer and Olaf Enge-Rosenblatt provide a high-level review of [AI solutions](https://semiengineering.com/artificial-intelligence-for-industrial-applications/) in semi-conductor engineering and fabrication.

https://youtu.be/kGsjxeLxMXg
https://youtu.be/qB2fLlxEBIQ
https://youtu.be/nLWEijWU3Ig
https://youtu.be/s4F_UN9MbSU


3. Quizzes: Introducing AI and ML

* Which of the following statements are accurate?
- Artificial intelligence is the ability for a computer to simulate human cognitive behavior
- ML is a subset of AI
* What is the correct order for the process of training for AI and ML 
  Step 1: build an AI system using techniques which include ML
  Step 2: the AI system trains the ML models 
  Step 3: data scientists optimize the ML models 
  Step 4: continue training until accuracy is sufficient 
* Thinking about AI and ML in Practice: Choose an industry familiar to you and research three examples of ways that artificial intelligence or machine learning are shaping that industry. Briefly describe one of these projects and its impact on the relevant industry.


4. Common AI and ML Workloads
Workloads - A workload is a type of problem we want to solve. For example, one workload is computer vision, and an example of computer vision to review a folder full of images and tag those images which include pictures of either cats or dogs.
https://youtu.be/CQgFNJpVZCU 
There are five common workloads for artificial intelligence.
1. computer vision 
2. prediction, forecasting and anomaly detection (numerical data)
3. nlp 
4. knowledge mining 
5. conversational ai

Computer Vision
https://youtu.be/WWFj4UdqZJY 
Computer vision is the process of interpreting the world visually. We train models on videos or images, typically to recognize some object, state, or interaction. Six common implementations of computer vision are:

    - Image classification: Define the subject of an image. For example, an image classification system could pick out the most prominent actor or thing in a photograph, such as a person, a fruit bowl, or London's Big Ben tower clock.
   - Object detection: Determine whether a particular thing is in an image. An example of this would be a camera placed near a chicken coop which detects foxes or other predators and raises an alert based on this.
    - Semantic segmentation: Classify individual pixels in a photo as belonging to a particular thing. For example, a camera monitoring a busy road would generate an image, and then a semantic segmentation model could identify the individual vehicles on the road and highlight each vehicle with a separate color.
   - Image analysis: Image analysis provides us a textual description of who or what is in a photo. For example, suppose we have a photo of a man playing catch with a dog. An image analysis model might tell us that the man is throwing a tennis ball, that the man is wearing a blue cap, and that the dog is a yellow Labrador Retriever.
   - Facial detection and recognition: Identify whether there is a face in a photo. For example, you might want to count how many people enter a store. Using a video camera monitoring the entrance to the store, a facial detection model can identify the number of people who pass through into the store based on observing faces.
    - Optical character recognition (OCR): Read text from an image. For example, you might open a phone application which reads a menu written in a language. That application uses optical character recognition to read letters and words on the image. It can further connect to a service which translates those letters and words into another language, showing the menu items in your preferred language.

Prediction, Forecasting, and Anomaly Detection
https://youtu.be/jlvu4Zfv_1o
Prediction, forecasting, and anomaly detection are techniques intended to analyze data--typically numeric values--and generate an estimation. In the case of prediction and forecasting, we attempt to draw conclusions from the data. For example, suppose we want to estimate the value of a house. We might use input data such as the number of bedrooms, number of bathrooms, and square footage, as well as information on the school district, whether it has certain amenities, and the year it was built.

Anomaly detection intends to find errors or unusual activity in a system. It tends to be focused on a single measure, such as the temperature of a machine or the number of products listed on a marketplace. This kind of data is usually--but not always--time series in nature, and we emphasize trends and changes rather than specific values. That the temperature is 80 degrees Celsius is not necessarily a problem; the problem is that it should normally be 30 degrees Celsius.

Natural Language Processing
https://youtu.be/QCyVDOww5PU

Natural language processing (NLP) is the process of interpreting written or spoken language. We train models based on written documents or audio clips of speech. Three common implementations of natural language processing are:

    Text analytics: Analyze documents. There are several methods of analysis. One method is to extract phrases, such as finding every time a character in a novel uses a particular word. We can also enumerate the characters in a novel or pick out the places these characters visit over the course of a story. We can even evaluate the sentiment of text, understanding the moods of characters over the course of the book.
    Text translation: Translate text between languages. This allows a person speaking English to present to an audience of non-English speakers. The translation service interprets the speaker's text, translates it to another language, and displays that text on the screen as live captions.
    Text to speech: Interpret written text and speak it aloud. This kind of service has been around for decades, with improvements over time coming primarily in conveying meaning and nuance in the text using inflection and tone.

In addition, Microsoft has a cloud service called the Language Understanding Intelligent Service (LUIS), which accepts written or spoken inputs, processes those inputs, and allows developers to perform some action based on those inputs. For example, a person may speak a command to open the curtains in the living room. LUIS would interpret this command and could call a function to activate a physical device inside the house, opening the living room curtains.

Knowledge Mining

Knowledge mining is the process of extracting knowledge from vast amounts of information. In Azure, Azure Cognitive Search is the primary tool. It tags information in documents, allowing for easy, detailed searches of those documents.

Conversational AI
https://youtu.be/2J4XjgpBbFs
Conversational AI is another common workload. With this workload, we develop software agents intended to communicate directly with humans, typically in conversational format. One common example of this is a chatbot which interacts with you on a website. Another example of a conversational AI system would be a virtual agent, who might help you search on the market for a particular house based on the criteria most important to you.
Additional Resources

    The Microsoft hands-on [Computer Vision demo](https://aidemos.microsoft.com/computer-vision) provides an overview of services available in their Cognitive Services product which relate to vision. This includes analyzing and describing images, reading text from images, and recognizing celebrities or landmarks.
    Another hands-on demo from Microsoft allows you to use the [Language Understanding Intelligent Service](https://aidemos.microsoft.com/luis/demo) to control lights in a house. Use natural language commands to operate different lights in rooms based on context, such as "I would like to watch a movie now." or "Time to go to sleep." The demo also shows the limitations of language understanding, as there are many ways to phrase a problem which developers did not think about.
    [Microsoft has a data story](https://github.com/Microsoft/DataStoriesSamples/tree/master/samples/WarAndPeaceSentimentAnalysis) which uses sentiment analysis to observe the emotional states and relationships of characters throughout Leo Tolstoy's novel, War and Peace.
    Another example of computer vision in practice is this demo on [pixel-level land cover classification](https://github.com/Azure/pixel_level_land_classification). Data scientists trained a neural network to accept an aerial image as an input and return a lad cover label for each pixel in the image.



5. Quizzes: common AI and ML Workloads

Which of the following is not a common AI or ML workload? 
- NLP
- Knowledge Mining
- Conversational AI
- Literate Programming (correct answer)
- Computer Vision 

Great job! Literate programming is a software programming methodology, but is not related to artificial intelligence or machine learning.

Match the AI or ML to its specific workload:
Semantic segmentation -> computer Vision 
classifying objects->prediction and forecasting
tracking trends and changes->anomaly detection 
text to speech -> natural language processing
cognitive search ->knowledge mining 
Q&A maker -> conversational ai 

6. Responsible AI
https://youtu.be/HBygSGptb8s
Summary

The Responsible AI project is intended to serve as a framework for promoting ethical behavior when working with and deploying artificial intelligence systems. The project starts from the premise that artificial intelligence systems can affect our livelihoods and lives in significant fashion--at the extreme, we put our lives into self-driving cars and aircraft auto-pilot systems. Even in more pedestrian endeavors, an AI system can unintentionally harm humans. The goal of the Responsible AI project is to provide guidance to data scientists, data engineers, and operations specialists on how to create, deploy, and manage artificially intelligent code in a way which does not cause harm to others.

The Responsible AI project consists of six guidelines:

    Fairness: AI systems should treat all people fairly and not affect similarly situated groups in different ways.
    Reliability and Safety: Customers should be able to trust that AI solutions will perform reliably and safely within a clear set of parameters, as well as respond safely to unanticipated situations.
    Privacy and Security: AI systems should be secure and respect existing privacy laws.
    Inclusiveness: AI systems should engage and empower people and use inclusive design practices to eliminate unintentional barriers.
    Transparency: People should know how AI systems work and how they interact with data to make decisions.
    Accountability: Those who design and deploy AI systems are accountable for how their systems operate.

Additional Resources

    Microsoft has provided a set of resources around [Responsible AI](https://youtu.be/HBygSGptb8s). This includes descriptions of each guideline as well as tools to put these guidelines into practice.


7. Quizzes: Responsible AI 

Which of the following are NOT guiding principles of responsible AI? 
- Transparency
- Accuracy (correct) 
- Acountability
- Reliability
- completeness (correct) 

Understanding the risk of failure helps fulfill which guiding principle of responsible AI?
- fairness
- reliability and safety (correct) 
- privacy and security
- inclusiveness
- transparency
- accountability

Great job! Understanding what can happen if your AI system fails is critical to reliability and safety--if we don't know how the system can fail, we might not be able to guarantee that it will fail gracefully or safely.

Consider the following scenario:

Your team has created an AI system which helps price business loans to entrepreneurs. The system includes a model which takes in detailed demographic information about the entrepreneur (including race, ethnicity, age, political beliefs, and religion) as well as several hundred other inputs. The model returns a single output: the interest rate for the loan. Because of the level of complexity, it is not possible for anybody to explain how the system works in its entirety and the data science team want to put it out into production, making it available for use but not maintaining or monitoring the system. In addition, all data, including the entrepreneur's tax data for the past three years, is stored in Azure Blob Storage in a publicly accessible blob.

Which of the following responsible AI guidelines would this system violate?

(Select all that apply.)
- fairness (correct) 
- reliability and safety  
- privacy and security (correct) 
- inclusiveness
- transparency (correct)
- accountability (correct) 
Great job! This solution may technically be workable, but it is obvious that there are major problems with it from a responsible AI standpoint.

8. Exercise: Responsible AI 
Exercise: Responsible AI in Practice

We have looked at the responsible AI approach with its six key tenets:

    Fairness
    Reliability and safety
    Privacy and security
    Inclusiveness
    Transparency
    Accountability

These are important principles to keep in mind when building artificially intelligent agents, but applying these in practice may not be straightforward. It can be easy to focus on the "machine" part of artificial intelligence to the detriment of humans who deal directly with the agent or indirectly through the agent's actions.

Keep in mind that this human-AI interaction is critical for developing artificial intelligence responsibly.
Guidelines for Human-AI Interaction

Navigate to the Microsoft [AI Guidlines for Human-AI Interaction demo](https://aidemos.microsoft.com/guidelines-for-human-ai-interaction/demo).

This demo takes us through four phases of interaction between humans and artifically intelligent agents.

For each guideline, review the card text on the left-hand side as well as examples on the right-hand side. Then, select the next card to continue through the demo.

You'll use the knowledge from each of these guidelines to answer the following quizzes.

Which of the following is an example of supporting efficient correction?
- Making it easy for a user to reroute around unexpected road closures (correct) 
- Notifying a user who has missed an important meeting 
- Having a spell checker which marks misspellings while the user types a word rather than waiting for the complete word
- A navigation system rerouting a user automtically if the user misses a turn. 

Which of the following are examples of showing contextually relevant information to a user?
- recommending accessories when a person adds a product to a shopping cart. (correct) 
- Showing the current price of a stock when searching by the ticker name. (correct)
- Loading a home page when a user opens a new browser tab. 
- Providing the ability to dismiss suggestions by clicking an X
- Displaying prospective meeting attendees calednars when planning a meeting (correct) 

Match the system activity with its most relevant human-AI interaction guide. 
- If a user likes a particular post, explain how that changes the recommender algorithm. -> convey the consequences of user actions 
- Display a warning message if a user tries to navigate to a point with no possible routing -> scope of service when in doubt
- Based on the difficult level of functionality used in a product, tailor autmated help to the user's perceived level of experience -> learn from user behavior
- When correcting user behavior, use a tone and style which is appropriate for the user-> match relevant social norms

9. Responsible ML
https://youtu.be/8zNLgzO-9UE

Summary

As an analog to the Responsible AI project, the Responsible ML project is an effort to control machine learning models and protect users. The Responsible ML project consists of three key guidelines:

    Understand: We should understand our models, including knowing which factors play a role and to what extent they affect the outcome of the model. This ties in quite closely to the Responsible AI guidelines of transparency and fairness.
    Protect: We want to use tools and processes which protect data privacy at all times, even during training.
    Control: We should create audit trails and track the lineage of our models. This will help us ensure that the right model is producing the expected results in a production environment.

New Terms

    Differential privacy: A technique in which individual data points are modified with some constant error term. The end result is that the data points can no longer be tied back to specific locations but the distribution of this data remains the same in aggregate. For example, a dataset of police incidents may use differential privacy to protect accidental disclosure of information, such as knowledge of a domestic disturbance. The dataset would have each point (in latitude and longitude) enclosed in a circle of radius r, where r might be approximately one city block. We choose a random point within the circle and define that point as the location of the incident. On net, we know how many crimes there are in a particular neighborhood, but we do not necessarily know at which houses the incidents occur.
    Homomorphic encryption: A style of encryption which allows a developer or data scientist to perform calculations on encrypted data without decrypting it first. The result of these calculations will also be in an encrypted form and the decrypted result will be exactly the same as if we performed all of the operations on unencrypted data. This ensures that data scientists can work on data sets while maintaining maximum privacy, as they will not see the unencrypted data at any time.

Additional Resources

    Microsoft has a page dedicated to [Responsible ML guidelines](https://azure.microsoft.com/en-us/services/machine-learning/responsibleml/). This page includes introductory videos, webinars, and examples of tools which promote responsible use of machine learning in practice.
    Microsoft Research has a page containing information on [homomorphic encryption](https://www.microsoft.com/en-us/research/project/homomorphic-encryption/). This includes information about the topic at a high level, as well as information on specific libraries like Microsoft SEAL, which makes homomorphic encryption available to developers.


10. Quizzes: Responsible ML
The responsible ML guideline of understanding is a combination of which responsible AI guidelines? 
- Fairness (correct)
- Realiability and Safety 
- privacy and security
- inclusiveness
- Transparency (correct)
- accountability 
Great job! The responsible ML guidelines do not overlap perfectly with responsible AI guidelines, but the principle of understanding your machine learning models does tie in closely with the principles of transparency and fairness.

The Importance of Model Control

In your own words, describe why it is important for responsible machine learning specialists to have audit trails and track the lineage of models.

Thanks for your thoughts! It is critical to control which machine learning model is out in production for several reasons. For example, we don't want a bad actor to release a malicious version of our model which denies bank loans to people for inappropriate reasons, or for a hiring system which guarantees that the developer's friends will be hired at high salaries. We want to be able to trace how the models have been developed, how they have changed over time, and ensure that the one providing answers is in fact what we expect it to be.

Which of the following are examples of techniques to promote the responsible ML guideline of protection?
- Use differential privacy 
- Encrypt data at rest 
- Use confidential machine learning techniques
- Use homomorphic encryption to prevent data scientists from seeing the actual data. 
That's right: all of these techniques help us protect our users' data and privacy as we develop machine learning models.

11. Edge Cases
https://youtu.be/m5b2mCLG8RM
Ongoing process. Need to continually look at issues and work on them.  Do not "set and forget" 

Summary

What we have covered in this lesson is an incomplete survey of artificial intelligence. There are additional workloads which are less common but still fall into the realm of artificial intelligence. Some of these include:

    Autonomous systems, which control things like lighting, ventilation, and security.
    Optimization of difficult problems. One example of this is the use of a technique known as [genetic algorithms](https://www.hindawi.com/journals/ijap/2014/729208/) to design smart antennas. Antenna design is a complicated problem and genetic algorithms provide an opportunity to search within the space of possible solutions for something better than what we have today.
    Planning systems, which take a set of general facts about the effects of specific actions, facts about a particular situation, and an end goal. The system then generates a strategy to achieve the goal.

Regardless of the workload, however, it is important to keep the Responsible AI and Responsible ML guidelines in mind. It is also important to note that these are starting points, not conclusions; they are something we keep purposefully in mind throughout the development, deployment, and maintenance of artificial intelligence solutions.
Additional Resources

    Microsoft has a page dedicated to [Responsible ML guidelines](https://azure.microsoft.com/en-us/services/machine-learning/responsibleml/). This page includes introductory videos, webinars, and examples of tools which promote responsible use of machine learning in practice.
    The editors at Brainz include a series of cases in which researchers, engineers, and developers have used [genetic algorithms](https://www.brainz.org/15-real-world-applications-genetic-algorithms/) to solve problems in a variety of fields.
    John Holland provides an [introduction to the concept behind genetic algorithms](http://www2.econ.iastate.edu/tesfatsi/holland.gaintro.htm). This approach, based on tenets of evolutionary biology, works well in a variety of constrained optimization scenarios.
    John Koza provides an [introduction to genetic programming](http://www.genetic-programming.com/gpanimatedtutorial.html), a variant on John Holland's concept of genetic algorithms.



12. Lesson Review 
https://youtu.be/e5JdIA7U-hw
Summary

This lesson introduced you to key terminology in artificial intelligence and machine learning. In the lesson, we learned:

    What artificial intelligence and machine learning are, as well as how machine learning is a subset of artificial intelligence.
    There are five common artificial intelligence and machine learning workloads, including:
        Computer vision
        Prediction, forecasting, and anomaly detection
        Natural language processing
        Knowledge mining
        Conversational AI
    The Responsible Artificial Intelligence project provides six guidelines for ethical artificial intelligence projects:
        Fairness
        Reliability and safety
        Privacy and security
        Inclusiveness
        Transparency
        Accountability
    The Responsible Machine Learning project has three pillars for ethical machine learning projects:
        Understand the model
        Protect the data
        Control model deployment

With this information, we now have the foundation that we need in order to jump into the remaining lessons of this nanodegree.



13. Glossary 
* Artificial Intelligence: the ability for a computer to simulate human cognitive behavior.
* Computer vision: the process of interpreting the world visually. We train models on videos or images, typically to recognize some object, state, or interaction.
* Differential privacy: A technique in which individual data points are modified with some constant error term. The end result is that the data points can no longer be tied back to specific locations but the distribution of this data remains the same in aggregate. For example, a dataset of police incidents may use differential privacy to protect accidental disclosure of information, such as knowledge of a domestic disturbance. The dataset would have each point (in latitude and longitude) enclosed in a circle of radius r, where r might be approximately one city block. We choose a random point within the circle and define that point as the location of the incident. On net, we know how many crimes there are in a particular neighborhood, but we do not necessarily know at which houses the incidents occur.
* Homomorphic encryption: A style of encryption which allows a developer or data scientist to perform calculations on encrypted data without decrypting it first. The result of these calculations will also be in an encrypted form and the decrypted result will be exactly the same as if we performed all of the operations on unencrypted data. This ensures that data scientists can work on data sets while maintaining maximum privacy, as they will not see the unencrypted data at any time.
* Knowledge mining: the process of extracting knowledge from vast amounts of information. In Azure, Azure Cognitive Search is the primary tool. It tags information in documents, allowing for easy, detailed searches of those documents.
* Language Understanding Intelligent Service (LUIS): a service which accepts written or spoken inputs, processes those inputs, and allows developers to perform some action based on those inputs.
* Machine Learning: the process of combining algorithms and data to allow a computer to learn without human intervention.
* Natural language processing (NLP) is the process of interpreting written or spoken language. We train models based on written documents or audio clips of speech.
* Responsible AI: The Responsible AI project is intended to serve as a framework for promoting ethical behavior when working with and deploying artificial intelligence systems. It consists of six guidelines:
* Fairness: AI systems should treat all people fairly and not affect similarly situated groups in different ways.
* Reliability and Safety: Customers should be able to trust that AI solutions will perform reliably and safely within a clear set of parameters, as well as respond safely to unanticipated situations.
* Privacy and Security: AI systems should be secure and respect existing privacy laws.
* Inclusiveness: AI systems should engage and empower people and use inclusive design practices to eliminate unintentional barriers.
* Transparency: People should know how AI systems work and how they interact with data to make decisions.
* Accountability: Those who design and deploy AI systems are accountable for how their systems operate.
* Responsible ML: The Responsible ML project is an effort to control machine learning models and protect users. It consists of three key guidelines:
* Understand: We should understand our models, including knowing which factors play a role and to what extent they affect the outcome of the model. This ties in quite closely to the Responsible AI guidelines of transparency and fairness.
* Protect: We want to use tools and processes which protect data privacy at all times, even during training.
* Control: We should create audit trails and track the lineage of our models. This will help us ensure that the right model is producing the expected results in a production environment.
* Strong Artificial Intelligence: a system which exhibits a human's ability to generalize and solve a variety of problems, including learning how to solve new problems without direct human programming. As of today, there are no strong AI systems in the world, and there remains debate in the academic community around whether strong AI is achievable.
* Super Artificial Intelligence: a system which surpasses a human's ability to generalize and solve problems. This is like strong AI, but the expectation is that the system is superior in every domain of problem-solving capability.
* Weak Artificial Intelligence: a narrow application of intelligence, focused on solving one problem. An example of this is a system which counts people who enter or leave a bus. All artificial intelligence systems today are considered weak AI.

## [Lesson 4: Machine Learning](https://classroom.udacity.com/courses/ud099/lessons/d2a77498-3bd4-466d-90ce-9bf572a2c467/concepts/9b018ae4-efe5-4f96-b283-18207bc2420d)
 1. Introduction and Overview 
 2. Introducing ML
 3. Training and Evaluation 
 4. Evaluation Metrics
 5. Quizzes: Introducing Machine 
 6. Main Approaches to ML
 7. Quizzes: Main Approaches to ML
 8. Core Tasks of Building a ML
 9. Quzzes: Core Tasks of Building 
 10. Exercise Model Training 
 11. Solution Model Training 
 12. Exercise Deploying and Testing
 13. Solution Deploying and Testing 
 14. A lap around azure ML
 15. Quizzes a lap around azure ml
 16. ...

## Lesson 5 
## Lesson 6
## Lesson 7 
